Expose vcpus as multiple cores in a smaller number of sockets,
by adjusting the cpuid responses appropriately.

diff -r 941ab17c1379 tools/libxc/xc_domain.c
--- a/tools/libxc/xc_domain.c
+++ b/tools/libxc/xc_domain.c
@@ -740,6 +740,20 @@ int xc_domain_get_tsc_info(xc_interface 
 }
 
 
+int xc_domain_set_cores_per_socket(xc_interface *xch,
+                                   uint32_t domid,
+                                   uint32_t cores_per_socket)
+{
+    struct xen_domctl domctl =
+    {
+        .cmd = XEN_DOMCTL_setcorespersocket,
+        .domain = domid,
+        .u.corespersocket.cores_per_socket = cores_per_socket,
+    };
+
+    return do_domctl(xch, &domctl);
+}
+
 int xc_domain_maximum_gpfn(xc_interface *xch, domid_t domid)
 {
     return do_memory_op(xch, XENMEM_maximum_gpfn, &domid, sizeof(domid));
diff -r 941ab17c1379 tools/libxc/xenctrl.h
--- a/tools/libxc/xenctrl.h
+++ b/tools/libxc/xenctrl.h
@@ -1239,6 +1239,10 @@ int xc_domain_get_tsc_info(xc_interface 
 
 int xc_domain_disable_migrate(xc_interface *xch, uint32_t domid);
 
+int xc_domain_set_cores_per_socket(xc_interface *xch,
+                                   uint32_t domid,
+                                   uint32_t cores_per_socket);
+
 int xc_domain_maximum_gpfn(xc_interface *xch, domid_t domid);
 
 int xc_domain_increase_reservation(xc_interface *xch,
diff -r 941ab17c1379 xen/arch/x86/hvm/svm/svm.c
--- a/xen/arch/x86/hvm/svm/svm.c
+++ b/xen/arch/x86/hvm/svm/svm.c
@@ -1374,14 +1374,32 @@ static void svm_cpuid_intercept(
 {
     unsigned int input = *eax;
     struct vcpu *v = current;
+    unsigned int cps = v->domain->cores_per_socket;
 
     hvm_cpuid(input, eax, ebx, ecx, edx);
 
     switch (input) {
+    case 1:
+        if ( cps > 0 )
+        {
+            /* fake out #vcpus and inform guest of #cores per package */
+            *ebx &= 0xFF00FFFF;
+            *ebx |= ((cps & 0xFF) << 16);
+        }
+        break;
     case 0x80000001:
         /* Fix up VLAPIC details. */
         if ( vlapic_hw_disabled(vcpu_vlapic(v)) )
             __clear_bit(X86_FEATURE_APIC & 31, edx);
+        if ( cps > 0 )
+            *ecx |= cpufeat_mask(X86_FEATURE_CMP_LEGACY);
+        break;
+    case 0x80000008:
+        if ( cps > 0 )
+        {
+            *ecx &= 0xFFFF0F00;
+            *ecx |= (cps - 1) & 0xFF;
+        }
         break;
     case 0x8000001c: 
     {
diff -r 941ab17c1379 xen/arch/x86/hvm/vmx/vmx.c
--- a/xen/arch/x86/hvm/vmx/vmx.c
+++ b/xen/arch/x86/hvm/vmx/vmx.c
@@ -1773,11 +1773,32 @@ static void vmx_cpuid_intercept(
     unsigned int input = *eax;
     struct segment_register cs;
     struct vcpu *v = current;
+    unsigned int cps = v->domain->cores_per_socket;
 
     hvm_cpuid(input, eax, ebx, ecx, edx);
 
     switch ( input )
     {
+        case 0x00000001:
+            if ( cps > 0 )
+            {
+                /* to fake out #vcpus per socket first force on HT/MC */
+                *edx |= cpufeat_mask(X86_FEATURE_HT);
+                /* fake out #vcpus and inform guest of #cores per package */
+                *ebx &= 0xFF00FFFF;
+                *ebx |= (((cps * 2) - 1) << 16);
+            }
+            break;
+
+        case 0x00000004:
+            if ( cps > 0 )
+            {
+                /* fake out cores per socket */
+                *eax &= 0x3FFF; /* one thread, one core */
+                *eax |= (((cps * 2) - 1) << 26);
+            }
+            break;
+
         case 0x80000001:
             /* SYSCALL is visible iff running in long mode. */
             vmx_get_segment_register(v, x86_seg_cs, &cs);
diff -r 941ab17c1379 xen/common/domctl.c
--- a/xen/common/domctl.c
+++ b/xen/common/domctl.c
@@ -900,6 +900,44 @@ long do_domctl(XEN_GUEST_HANDLE_PARAM(xe
         break;
     }
 
+    case XEN_DOMCTL_setcorespersocket:
+    {
+        struct domain *d;
+
+        ret = -ESRCH;
+        d = rcu_lock_domain_by_id(op->domain);
+
+        if ( d != NULL )
+        {
+            unsigned int cps = op->u.corespersocket.cores_per_socket;
+
+            /* Toolstack is permitted to set this value exactly once. */
+            if ( d->cores_per_socket != 0 )
+                ret = -EEXIST;
+
+            /* Only meaningful for HVM domains. */
+            else if ( !has_hvm_container_domain(d) )
+                ret = -EOPNOTSUPP;
+
+            /* Cores per socket is strictly within the bounds of max_vcpus. */
+            else if ( cps < 1 || cps > d->max_vcpus )
+                ret = -EINVAL;
+
+            /* Cores per socket must exactly divide max_vcpus. */
+            else if ( d->max_vcpus % cps != 0 )
+                ret = -EDOM;
+
+            else
+            {
+                d->cores_per_socket = cps;
+                ret = 0;
+            }
+
+            rcu_unlock_domain(d);
+        }
+    }
+    break;
+
     default:
         ret = arch_do_domctl(op, d, u_domctl);
         break;
diff -r 941ab17c1379 xen/include/public/domctl.h
--- a/xen/include/public/domctl.h
+++ b/xen/include/public/domctl.h
@@ -971,6 +971,12 @@ DEFINE_XEN_GUEST_HANDLE(xen_domctl_runst
 /* Some vcpus are runnable, some are blocked */
 #define DOMAIN_RUNSTATE_partial_contention 5
 
+struct xen_domctl_corespersocket {
+    uint32_t cores_per_socket;
+};
+
+typedef struct xen_domctl_corespersocket xen_domctl_corespersocket_t;
+DEFINE_XEN_GUEST_HANDLE(xen_domctl_corespersocket_t);
 
 struct xen_domctl {
     uint32_t cmd;
@@ -1049,6 +1055,7 @@ struct xen_domctl {
 #define XEN_DOMCTL_gdbsx_pausevcpu             1001
 #define XEN_DOMCTL_gdbsx_unpausevcpu           1002
 #define XEN_DOMCTL_gdbsx_domstatus             1003
+#define XEN_DOMCTL_setcorespersocket           4001
     uint32_t interface_version; /* XEN_DOMCTL_INTERFACE_VERSION */
     domid_t  domain;
     union {
@@ -1103,6 +1110,7 @@ struct xen_domctl {
         struct xen_domctl_set_virq_handler  set_virq_handler;
         struct xen_domctl_set_max_evtchn    set_max_evtchn;
         struct xen_domctl_runstate_info     domain_runstate;
+        struct xen_domctl_corespersocket    corespersocket;
         struct xen_domctl_gdbsx_memio       gdbsx_guest_memio;
         struct xen_domctl_set_broken_page_p2m set_broken_page_p2m;
         struct xen_domctl_cacheflush        cacheflush;
diff -r 941ab17c1379 xen/include/xen/sched.h
--- a/xen/include/xen/sched.h
+++ b/xen/include/xen/sched.h
@@ -426,6 +426,8 @@ struct domain
     spinlock_t runstate_lock;
     atomic_t runstate_missed_changes;
     domain_runstate_info_t runstate;
+
+    unsigned int cores_per_socket;
 };
 
 struct domain_setup_info
